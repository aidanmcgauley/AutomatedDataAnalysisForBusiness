{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66d1f47",
   "metadata": {},
   "source": [
    "# Chapter 3 Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a37d8",
   "metadata": {},
   "source": [
    "In this section I'll be trying to automate the creation of a data collection and analysis plan that others can easily follow for a specified metric and industry.\n",
    "I will also attempt to prompt the AI to carry out the analysis plan which will include the following steps:\n",
    "\n",
    "    - Outline the steps of the high-level data collection and analysis plan.\n",
    "    \n",
    "    Data collection steps:\n",
    "    - Generate a list of possible sources of data along with URL's.\n",
    "    - Iterate through a list of URL's searching for downloadable data.\n",
    "    - Download the data.\n",
    "    - Categorise the obtained data into numeric/textual.\n",
    "    \n",
    "    Data analysis steps:\n",
    "    - Review the collected data and suggest useful operations and visualizations to be carried out.\n",
    "    - Prompt chatgpt to then dynamically generate python code to execute the operations and graph plotting that it suggests.\n",
    "    - Validate code snippets\n",
    "    - Execute code\n",
    "    - Validate the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078d7b4",
   "metadata": {},
   "source": [
    "## Setup - Imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720e7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9780af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "WEBPILOT_API_KEY = \"d8684e9c2d7246748111bf8da0e6cd52\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9c4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpilot_url = \"https://preview.webpilotai.com/api/v1/watt\"\n",
    "webpilot_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer d8684e9c2d7246748111bf8da0e6cd52\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a7845",
   "metadata": {},
   "source": [
    "## Set the industry and metric to be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"time spent on sourcing stock per unit of stock\"\n",
    "industry = \"vintage banjo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae72082",
   "metadata": {},
   "source": [
    "## ChatGPT standard query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91344754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_standard_query(prompt, context=None):\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a skilled data analyst with experience in collecting, processing, and interpreting complex datasets. Your goal is to assist the user in devising data collection and analysis strategies.\"},\n",
    "        {\"role\": \"user\", \"content\": context if context else \"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    query_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return query_response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67463f65",
   "metadata": {},
   "source": [
    "## ChatGPT and Webpilot query function chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef195d",
   "metadata": {},
   "source": [
    "Call the 'webpilot_chatgpt_query' function, which will then call the other functions.\n",
    "\n",
    "URL's can optionally be passed in for Webpilot. (This is useful when searching for downloadable data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33bdf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webpilot_chatgpt_query(question, urls=None):\n",
    "    try:\n",
    "        # First, ask the WebPilot API\n",
    "        webpilot_response = ask_webpilot(question, urls)\n",
    "\n",
    "        if webpilot_response:\n",
    "            # If we got a response, ask the ChatGPT API to generate a human-like response\n",
    "            chatgpt_response = ask_chatgpt(question, webpilot_response)\n",
    "\n",
    "            if chatgpt_response:\n",
    "                return chatgpt_response\n",
    "\n",
    "        return \"I'm sorry, I couldn't find an answer to your question.\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892882f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_webpilot(question, urls=None):\n",
    "    print(\"Asking webpilot..\")\n",
    "    # Prepare the data for the WebPilot API\n",
    "    data = {\"content\": question}\n",
    "    if urls:\n",
    "        data[\"content\"] += \" \" + \" \".join(urls)\n",
    "\n",
    "    # Send a POST request to the WebPilot API\n",
    "    try:\n",
    "        response = requests.post(webpilot_url, headers=webpilot_headers, data=json.dumps(data), timeout=30)\n",
    "    except requests.Timeout:\n",
    "        print(\"The request timed out\")\n",
    "        return None\n",
    "\n",
    "    # Check the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"WebPilot response:\", response.json())  # Print the response\n",
    "        return response.json()[\"content\"]\n",
    "    else:\n",
    "        print(\"WebPilot error:\", response.status_code)  # Print the error code\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b012a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_chatgpt(question, webpilot_response):\n",
    "    print(\"Asking chatgpt..\")\n",
    "    # Set the OpenAI API key\n",
    "    openai.api_key = \"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\"\n",
    "\n",
    "    # Prepare the data for the ChatGPT API\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a skilled data analyst with experience in collecting, processing, and interpreting complex datasets. Your goal is to assist the user in devising data collection and analysis strategies.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": webpilot_response},\n",
    "    ]\n",
    "\n",
    "    # Send a request to the ChatGPT API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Check the response\n",
    "    if response:\n",
    "        print(\"ChatGPT response: \", response.choices[0].message['content'])\n",
    "        return response.choices[0].message['content']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2caf574",
   "metadata": {},
   "source": [
    "## Create prompt to generate analysis plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a322e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = f\"\"\"You are an expert data analyst\n",
    "                who excels at identifying successes and issues for businesses within an industry, \n",
    "                and using that information to \n",
    "                provide recommendations to decision makers which have a high impact.\n",
    "                It is your job to come up with a detailed \n",
    "                data collection and analysis plan for a specified metric.\n",
    "                Start with a high level description of the plan in a step by step format. \n",
    "                Then progressively go into more detail, describing fully each of the steps\n",
    "                involved in data collection and data analysis.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Generate a detailed analysis plan for the metric '{metric}' \n",
    "                in the {industry} industry \n",
    "                given this context: {context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b110e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp2 = gpt_standard_query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23eabb83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Define the objective and goal of the analysis \n",
      "- The objective is to analyze the time spent on sourcing stock per unit of stock in the vintage banjo industry. \n",
      "- The goal is to identify inefficiencies and opportunities for improvement in the sourcing process, ultimately leading to recommendations for reducing the time spent and increasing productivity.\n",
      "\n",
      "Step 2: Identify the data sources\n",
      "- Explore potential data sources such as:\n",
      "  - Internal databases or systems (e.g., inventory management system, purchase order system)\n",
      "  - External sources (e.g., industry reports, competitor information)\n",
      "  - Surveys or interviews with relevant stakeholders (e.g., stock managers, employees involved in the sourcing process)\n",
      "\n",
      "Step 3: Determine the data collection methods\n",
      "- Decide on the best methods for collecting relevant data, considering factors such as time, cost, and accuracy:\n",
      "  - Extract data from internal databases or systems: Identify the necessary data fields and establish a process for data extraction.\n",
      "  - Collect external data sources: Gather industry reports, competitor information, or any relevant third-party data.\n",
      "  - Conduct surveys or interviews: Prepare a questionnaire or interview guide to collect qualitative and quantitative insights from stakeholders.\n",
      "\n",
      "Step 4: Clean and validate the data\n",
      "- Perform data cleaning and validation to ensure accuracy and consistency:\n",
      "  - Remove any duplicate records or irrelevant data.\n",
      "  - Handle missing values by imputation or considering their impact on the analysis.\n",
      "  - Validate data against predefined criteria to identify any inconsistencies or outliers.\n",
      "\n",
      "Step 5: Calculate the metric 'time spent on sourcing stock per unit of stock'\n",
      "- Determine the formula for calculating the metric, based on the available data.\n",
      "- Calculate the time spent on sourcing stock per unit of stock for each relevant dataset or dimension (e.g., by product, by supplier, by location).\n",
      "- Aggregate the results to obtain an overall picture of the sourcing process efficiency.\n",
      "\n",
      "Step 6: Explore relationships and patterns\n",
      "- Perform exploratory data analysis to identify any trends, patterns, or correlations between the metric and other variables:\n",
      "  - Use statistical methods and visualization techniques to analyze the data.\n",
      "  - Examine relationships between the time spent metric and factors such as product type, supplier, location, or any other relevant variables.\n",
      "  - Identify any notable variations or outliers that may shed light on specific areas of improvement or success.\n",
      "\n",
      "Step 7: Identify opportunities for improvement\n",
      "- Analyze the findings to pinpoint areas of inefficiency and opportunities for improvement:\n",
      "  - Compare the metric across different categories or dimensions to identify variations.\n",
      "  - Identify potential bottlenecks or factors affecting the time spent on sourcing stock.\n",
      "  - Look for any specific patterns or correlations that suggest areas for improvement.\n",
      "\n",
      "Step 8: Provide recommendations\n",
      "- Based on the analysis, develop actionable recommendations for decision-makers:\n",
      "  - Present the findings and highlight areas of success and issues.\n",
      "  - Provide specific recommendations on how to reduce the time spent on sourcing stock, increase productivity, and improve efficiency.\n",
      "  - Consider the feasibility, impact, and cost-effectiveness of each recommendation.\n",
      "\n",
      "Step 9: Monitor and evaluate\n",
      "- Establish a process for ongoing monitoring and evaluation of the metric:\n",
      "  - Set up regular data collection and analysis to track changes in the time spent metric over time.\n",
      "  - Monitor the implementation and impact of the recommendations.\n",
      "  - Continuously evaluate the effectiveness of any interventions or improvements made.\n",
      "\n",
      "Step 10: Iterate and refine\n",
      "- Continuously refine the analysis plan based on feedback, new data sources, or changing business needs:\n",
      "  - Incorporate new data sources or metrics as they become available.\n",
      "  - Adapt the analysis plan to address emerging challenges or insights.\n",
      "  - Repeat the analysis periodically to track progress and identify new opportunities.\n"
     ]
    }
   ],
   "source": [
    "print(resp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0915847",
   "metadata": {},
   "source": [
    "## Alternative using langchain with serp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6bc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1cc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ['SERPAPI_API_KEY'] = \"e52dfccf2ffe6c78e8132d065cb7d1005027484d742b8c4a24a75521a34aff53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21866adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.8)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a573e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_plan(metric, industry, context):\n",
    "\n",
    "    prompt = f\"\"\"Generate a detailed analysis plan for the metric '{metric}' \n",
    "                in the {industry} industry \n",
    "                given this context: {context}\"\"\"\n",
    "\n",
    "    return agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3caf4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a detailed analysis plan for the metric '{metric}' given this context: {context}\"\n",
    "# Main program\n",
    "metric = \"time spent on sourcing per unit of stock\"\n",
    "industry = \"vintage banjo\"\n",
    "context = \"\"\"You are an expert data analyst\n",
    "                who excels at identifying successes and issues for businesses within an industry, \n",
    "                and using that information to \n",
    "                provide recommendations to decision makers which have a high impact.\n",
    "                It is your job to come up with a detailed data analysis plan \n",
    "                for a specified metric. \n",
    "                Start with a high level description of the analysis in a step by step format. \n",
    "                Then progressively go into more detail, describing fully each of the steps, \n",
    "                the type of data that you will try to find,\n",
    "                the ideal column format for the data,\n",
    "                the operations you will carry out on the data,\n",
    "                and the graphs you would use.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee8d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to come up with a clear and comprehensive plan to source and analyze data \n",
      "        related to the specified metric.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock analysis plan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe selling stockholders may sell common stock from time to time in the principal market on which the stock is traded at the prevailing market price or in ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not the kind of information I need to answer the question.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWhile piano sales hovered around 200,000 units per year during that time, guitar sales increased 400%, surging from 300,000 units in 1958 to 1.5 million in ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information looks promising.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis paper aims to explore the phenomenon of impulse buying in the fashion industry. The online and offline channels are compared to ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not quite what I am looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe answer is you spend a lot of time digging. The data in these pages comes from a variety of sources—import and export data as compiled by the World Trade ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is more relevant to my question.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan step by step\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe purchase price, the Offering Price per Interest times the number of Interests purchased, will be payable in cash at the time of subscription.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not what I am looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis paper aims to explore the phenomenon of impulse buying in the fashion industry. The online and offline channels are compared to ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan detailed\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe concert a day later was a rollicking affair of wailing classic- and twangy country-blues and a smattering of world-inspired music including ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan step by step detailed\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis Post-Qualification Amendment relates to the offer and sale of series of interest, as described below, to be issued by RSE Collection, LLC (the “Company,” “ ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis paper aims to explore the phenomenon of impulse buying in the fashion industry. The online and offline channels are compared to ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan template\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe maps in this book were produced by the Map Design Unit of The World Bank. The boundaries, colors, denominations, and any other information shown on these ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan example\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe maps in this book were produced by the Map Design Unit of The World Bank. The boundaries, colors, denominations, and any other information shown on these ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis paper aims to explore the phenomenon of impulse buying in the fashion industry. The online and offline channels are compared to ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan detailed example\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe concept of collecting data to understand how and where an organization is spending its money is not a new one. Documenting purchasing has always been a best.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan detailed step by step\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPresentation regarding old world bluestem invasive grass-Michael Hassett, Chairman,. Conservation District. II. UNFINISHED BUSINESS. Ill.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is still not what I'm looking for.\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry time spent on sourcing per unit of stock data analysis plan step by step\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe purchase price, the Offering Price per Interest times the number of Interests purchased, will be payable in cash at the time of subscription.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Generate a detailed analysis plan for the metric 'time spent on sourcing per unit of stock' \\n                in the vintage banjo industry \\n                given this context: You are an expert data analyst\\n                who excels at identifying successes and issues for businesses within an industry, \\n                and using that information to \\n                provide recommendations to decision makers which have a high impact.\\n                It is your job to come up with a detailed data analysis plan \\n                for a specified metric. \\n                Start with a high level description of the analysis in a step by step format. \\n                Then progressively go into more detail, describing fully each of the steps, \\n                the type of data that you will try to find,\\n                the ideal column format for the data,\\n                the operations you will carry out on the data,\\n                and the graphs you would use.\", 'output': 'Agent stopped due to iteration limit or time limit.'}\n"
     ]
    }
   ],
   "source": [
    "analysis = generate_analysis_plan(metric, industry, context)\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583a6ab",
   "metadata": {},
   "source": [
    "## Function using langchain/serpapi to search online for downloadable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4e3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for data\n",
    "def find_data(metric, industry):\n",
    "    \n",
    "    # Loop until suitable csv file found.\n",
    "    # Max repeats prevents continuous loop using api resources if suitable link not found.\n",
    "    max_repeats = 2\n",
    "    repeats = 0\n",
    "    data_url = None\n",
    "\n",
    "    tried_sources = []\n",
    "  \n",
    "    while data_url is None and repeats < max_repeats:\n",
    "        print(\"Entering loop\")\n",
    "        \n",
    "        data_prompt = f\"\"\"You are an expert data analyst\n",
    "                    who excels at identifying successes and issues for businesses within an industry, \n",
    "                    and using that information to \n",
    "                    provide recommendations to decision makers which have a high impact.\n",
    "                    In order to execute your data analysis plan,\n",
    "                    you need a dataset containing data on this metric: {metric}.\n",
    "                    The dataset must be related to businesses in the {industry} industry.\n",
    "                    The dataset must contain numeric values. based on the metric.\n",
    "                    Please search the web for a relevant CSV dataset. \n",
    "                    Provide the direct URL to the downloadable CSV file.\"\"\"\n",
    "\n",
    "        if tried_sources:\n",
    "            data_prompt += f\" Do not suggest any of these sources again: {tried_sources}\"\n",
    "\n",
    "        data_response = agent(data_prompt)\n",
    "        #print(type(data_response))\n",
    "        #print(data_response)\n",
    "    \n",
    "        # extract url\n",
    "        import re\n",
    "        url_match = re.search(r\"(http.*\\.csv)\", data_response['output'])\n",
    "        print(url_match)\n",
    "        if url_match:\n",
    "            data_url = url_match.group(1)\n",
    "            break\n",
    "\n",
    "        repeats += 1\n",
    "\n",
    "        if repeats >= max_repeats:\n",
    "        \n",
    "            print(\"Reached max data search attempts\")\n",
    "            break\n",
    "\n",
    "    if data_url:\n",
    "        # Found URL\n",
    "        print(\"Found dataset:\", data_url)\n",
    "\n",
    "        import requests\n",
    "        response = requests.get(data_url)\n",
    "        with open('data.csv', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(\"Downloaded CSV data\")\n",
    "\n",
    "    else:\n",
    "        print(\"No data URL found\")\n",
    "        \n",
    "    return data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1462380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering loop\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to search for a CSV file that contains numeric values related to the vintage banjo industry\n",
      "Action: Search\n",
      "Action Input: CSV dataset vintage banjo industry sourcing stock\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHighest Price Sold: $180 (Vintage Vase $180) Average Price Sold: $26.25. Returns: 0. Money Spent on New Inventory This Week: $0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have found a CSV file containing the metric I need\n",
      "Action: Search\n",
      "Action Input: CSV dataset vintage banjo industry sourcing stock\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHighest Price Sold: $180 (Vintage Vase $180) Average Price Sold: $26.25. Returns: 0. Money Spent on New Inventory This Week: $0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to make sure the CSV file contains numeric values\n",
      "Action: Search\n",
      "Action Input: vintage banjo industry CSV dataset numeric values\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mhttps://github.com/openimages/dataset/blob/main/dict.csv\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have found a CSV file containing the metric I need with numeric values\n",
      "Final Answer: https://github.com/openimages/dataset/blob/main/dict.csv\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<re.Match object; span=(0, 56), match='https://github.com/openimages/dataset/blob/main/d>\n",
      "Found dataset: https://github.com/openimages/dataset/blob/main/dict.csv\n",
      "Downloaded CSV data\n"
     ]
    }
   ],
   "source": [
    "csv_path = find_data(metric, industry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba631c",
   "metadata": {},
   "source": [
    "## Create prompt to generate list of data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e705676",
   "metadata": {},
   "source": [
    "The last function wasn't successful in finding downloadable data for the industry. Alternative is to first generate a list of possible websites from webpilot/chatgpt before passing to the 'find_data' function to search the sites for csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cfaef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"amount of time a business spends on sourcing stock\"\n",
    "\n",
    "source_prompt = f\"\"\"You are an expert data analyst\n",
    "                    who excels at identifying successes and issues for businesses within an industry, \n",
    "                    and using that information to \n",
    "                    provide recommendations to decision makers which have a high impact.\n",
    "                    You are currently helping a business in the {industry} industry.\n",
    "                    \n",
    "                    In order to execute your data analysis plan,\n",
    "                    you need a dataset containing data on this metric: {metric}.\n",
    "                    \n",
    "                    Return a list of URL's for websites that may contain \n",
    "                    data relating to the metric. \n",
    "                    \"\"\"\n",
    "source_prompt2 = f\"\"\"You are an expert data analyst\n",
    "                    who excels at identifying successes and issues for businesses within an industry, \n",
    "                    and using that information to \n",
    "                    provide recommendations to decision makers which have a high impact.\n",
    "                    You are currently helping a business in the {industry} industry.\n",
    "                    \n",
    "                    In order to execute your data analysis plan,\n",
    "                    you need a dataset containing data on this metric: {metric}.\n",
    "                    \n",
    "                    Please provide a list of potential data sources for analyzing the metric. \n",
    "                    For each source, include the name of the source \n",
    "                    and the URL where the data can be accessed.\n",
    "                    \n",
    "                    Structure your results like this:\n",
    "                    [\n",
    "                        {{\"Source name\": \" \", \"url\": \" \"}},\n",
    "                        {{\"Source name\": \" \", \"url\": \" \"}},\n",
    "                        # ...\n",
    "                    ]\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba644490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking webpilot..\n",
      "WebPilot response: {'content': \"Here are a few websites that may contain data relating to the metric of the amount of time a vintage banjo business spends on sourcing stock:\\n\\n1. [Bill's Banjos](https://www.billsbanjos.com/buying%20banjos.htm): This website offers information on buying vintage banjos and may contain insights into the time required for sourcing stock.\\n\\n2. [Etsy - Vintage African Decorative Guitar Banjo Percussion Musical](https://www.etsy.com/il-en/listing/1266174304/vintage-african-decorative-guitar-banjo): This Etsy listing may provide information on the estimated delivery time for vintage banjos, which could indirectly indicate the time spent on sourcing stock.\\n\\n3. [Etsy - Vintage French Decorative Banjo Guitar Percussion Musical](https://www.etsy.com/fi-en/listing/1153495526/vintage-french-decorative-banjo-guitar): Similar to the previous Etsy listing, this may provide insights into the delivery time for vintage banjos.\\n\\n4. [The Music Emporium](https://themusicemporium.com/): This website specializes in high-end and vintage instruments and may have relevant data on sourcing stock.\\n\\n5. [Reverb](https://reverb.com/): Reverb is a marketplace for musical instruments, including vintage banjos. It may have information on sourcing time or insights from sellers.\\n\\nPlease note that while these websites may provide some relevant data, it is recommended to explore further within each website to find more specific information on the metric you are interested in.\"}\n",
      "Asking chatgpt..\n",
      "ChatGPT response:  Here are a few websites that may contain data relating to the metric of the amount of time a vintage banjo business spends on sourcing stock:\n",
      "\n",
      "1. [Banjo Hangout](https://www.banjohangout.org/): This online community for banjo enthusiasts may have discussions or forums where vintage banjo businesses could share insights on their sourcing processes and the time involved.\n",
      "\n",
      "2. [Vintage Banjo World](http://www.vintagebanjoworld.com/): This website focuses on vintage banjos and may have articles, resources, or forums that discuss the sourcing processes and time involved in acquiring vintage banjos.\n",
      "\n",
      "3. [The American Banjo Museum](https://www.americanbanjomuseum.com/): The museum's website may contain information, publications, or articles related to the history and acquisition of vintage banjos, which could provide insights into the time required for sourcing stock.\n",
      "\n",
      "4. [Vintage & Rare](https://www.vintageandrare.com/): This platform specializes in vintage and rare musical instruments, including banjos. It may have listings, insights from sellers, or discussions related to the sourcing process and the time it takes to find vintage banjos.\n",
      "\n",
      "5. [Banjohaven](http://www.banjohaven.com/): This website is a marketplace for banjos, including vintage models. It may offer insights into the sourcing time and availability of vintage banjos based on listings and discussions among sellers and buyers.\n",
      "\n",
      "Please note that these websites are provided as suggestions, and it may be necessary to explore further within each website to find specific data or conversations related to the amount of time vintage banjo businesses spend on sourcing stock.\n"
     ]
    }
   ],
   "source": [
    "resp3 = webpilot_chatgpt_query(source_prompt, \"https://google.co.uk/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b67be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few websites that may contain data relating to the metric of the amount of time a vintage banjo business spends on sourcing stock:\n",
      "\n",
      "1. [Banjo Hangout](https://www.banjohangout.org/): This online community for banjo enthusiasts may have discussions or forums where vintage banjo businesses could share insights on their sourcing processes and the time involved.\n",
      "\n",
      "2. [Vintage Banjo World](http://www.vintagebanjoworld.com/): This website focuses on vintage banjos and may have articles, resources, or forums that discuss the sourcing processes and time involved in acquiring vintage banjos.\n",
      "\n",
      "3. [The American Banjo Museum](https://www.americanbanjomuseum.com/): The museum's website may contain information, publications, or articles related to the history and acquisition of vintage banjos, which could provide insights into the time required for sourcing stock.\n",
      "\n",
      "4. [Vintage & Rare](https://www.vintageandrare.com/): This platform specializes in vintage and rare musical instruments, including banjos. It may have listings, insights from sellers, or discussions related to the sourcing process and the time it takes to find vintage banjos.\n",
      "\n",
      "5. [Banjohaven](http://www.banjohaven.com/): This website is a marketplace for banjos, including vintage models. It may offer insights into the sourcing time and availability of vintage banjos based on listings and discussions among sellers and buyers.\n",
      "\n",
      "Please note that these websites are provided as suggestions, and it may be necessary to explore further within each website to find specific data or conversations related to the amount of time vintage banjo businesses spend on sourcing stock.\n"
     ]
    }
   ],
   "source": [
    "print(resp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58505e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking webpilot..\n",
      "WebPilot response: {'content': '[\\n  {\"Source name\": \"Spend Analysis 101 | Complete Guide for Procurement\", \"url\": \"https://sievo.com/resources/spend-analysis-101\"},\\n  {\"Source name\": \"Procurement Analytics: The Ultimate Guide in 2023\", \"url\": \"https://sievo.com/resources/procurement-analytics-demystified\"},\\n  {\"Source name\": \"What Is Spend Analysis? - NetSuite\", \"url\": \"https://www.netsuite.com/portal/resource/articles/accounting/spend-analysis.shtml\"},\\n  {\"Source name\": \"Spend Analysis - What Is It, Procurement, Example, Benefits ...\", \"url\": \"https://www.wallstreetmojo.com/spend-analysis/\"},\\n  {\"Source name\": \"Sourcing Analytics - Coursera\", \"url\": \"https://www.coursera.org/learn/sourcinganalytics\"},\\n  {\"Source name\": \"Spend Analysis : Importance, Process & Examples\", \"url\": \"https://tipalti.com/spend-analysis/\"},\\n  {\"Source name\": \"The role of spend analytics in the next normal\", \"url\": \"https://www.mckinsey.com/capabilities/operations/our-insights/the-role-of-spend-analytics-in-the-next-normal\"},\\n  {\"Source name\": \"The big-supply-chain analytics landscape (Part 1)\", \"url\": \"https://www.mckinsey.com/capabilities/operations/our-insights/big-data-and-the-supply-chain-the-big-supply-chain-analytics-landscape-part-1\"},\\n  {\"Source name\": \"What is Supply Chain Analytics and Why is It Important?\", \"url\": \"https://www.techtarget.com/searcherp/definition/supply-chain-analytics\"}\\n]'}\n",
      "Asking chatgpt..\n",
      "ChatGPT response:  \n"
     ]
    }
   ],
   "source": [
    "resp4 = webpilot_chatgpt_query(source_prompt2, \"https://google.co.uk/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fbf94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I couldn't find an answer to your question.\n"
     ]
    }
   ],
   "source": [
    "print(resp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60489dd0",
   "metadata": {},
   "source": [
    "## Next, loop through the URL's searching them for downloadable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9888c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative function that takes a list of specific websites to search for downloadable data\n",
    "# The previous 'find_data' function using langchain kept looping without finding anything on its own\n",
    "# It might work when provided a list of websites\n",
    "\n",
    "def find_data(metric, industry, url_list):\n",
    "    \n",
    "    # Max repeats has been increased as a list of URL's will be provided to search for CSV files\n",
    "    max_repeats = 10\n",
    "    data_url = None\n",
    "\n",
    "    # Loop added this time to loop through a list of specific websites that were found earlier and passed in\n",
    "    for source in url_list:\n",
    "        source_name = source[\"Source name\"]\n",
    "        url = source[\"url\"]\n",
    "        repeats = 0\n",
    "        tried_sources = []\n",
    "        \n",
    "        print(f\"Searching in {source_name}\")\n",
    "      \n",
    "        while data_url is None and repeats < max_repeats:\n",
    "            print(\"Entering loop\")\n",
    "            \n",
    "            data_prompt = f\"\"\"You are an expert data analyst\n",
    "                        who excels at identifying successes and issues for businesses within an industry, \n",
    "                        and using that information to \n",
    "                        provide recommendations to decision makers which have a high impact.\n",
    "                        In order to execute your data analysis plan,\n",
    "                        you need a dataset containing data on this metric: {metric}.\n",
    "                        The dataset must be related to businesses in the {industry} industry.\n",
    "                        The dataset must contain numeric values based on the metric.\n",
    "                        Please search the web for a relevant CSV dataset at this URL: {url}\n",
    "                        Provide the direct URL to the downloadable CSV file.\"\"\"\n",
    "\n",
    "            if tried_sources:\n",
    "                data_prompt += f\" Do not suggest any of these sources again: {tried_sources}\"\n",
    "\n",
    "            data_response = webpilot_chatgpt_query(prompt=data_prompt, url=url)\n",
    "            # Extract url\n",
    "            import re\n",
    "            url_match = re.search(r\"(http.*\\.csv)\", data_response['output'])\n",
    "            print(url_match)\n",
    "            if url_match:\n",
    "                data_url = url_match.group(1)\n",
    "                break\n",
    "\n",
    "            repeats += 1\n",
    "            tried_sources.append(source_name)\n",
    "\n",
    "            if repeats >= max_repeats:\n",
    "                print(\"Reached max data search attempts\")\n",
    "                break\n",
    "\n",
    "        if data_url:\n",
    "            # Found URL\n",
    "            print(\"Found dataset:\", data_url)\n",
    "\n",
    "            import requests\n",
    "            response = requests.get(data_url)\n",
    "            with open('data.csv', 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            print(\"Downloaded CSV data\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"No data URL found in {source_name}\")\n",
    "\n",
    "    return data_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = find_data(metric, industry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856d173",
   "metadata": {},
   "source": [
    "## Functions to check data, get analysis methods, generate code, validate code, and validate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types  \n",
    "def check_data_types(csv_file):\n",
    "\n",
    "    #df = pd.read_csv(csv_file)\n",
    "    df = pd.read_csv(csv_file, on_bad_lines='skip')\n",
    "\n",
    "    # Get column details\n",
    "    numeric_cols = []\n",
    "    text_cols = []\n",
    "\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        if pd.api.types.is_numeric_dtype(dtype):\n",
    "            numeric_cols.append(col)\n",
    "        elif pd.api.types.is_string_dtype(dtype):\n",
    "            text_cols.append(col)\n",
    "        \n",
    "    # Print numeric column names\n",
    "    print(\"Numeric column headings:\")\n",
    "    for col in numeric_cols:\n",
    "        print(col)\n",
    "\n",
    "    return numeric_cols, text_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65651159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analysis suggestions\n",
    "def get_suggestions(metric, industry, numeric_cols, text_cols):\n",
    "\n",
    "    # Use spaCy to extract suggestions\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(ask_question(prompt))\n",
    "    suggestions = [chunk.text for sent in doc.sents for chunk in sent.noun_chunks]\n",
    "\n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e559b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(suggestions):\n",
    "  \n",
    "    code_snippets = []\n",
    "\n",
    "    for suggestion in suggestions:\n",
    "        prompt = f\"Please provide python code to implement this suggestion: {suggestion}\"\n",
    "        code = ask_question(prompt)\n",
    "        code_snippets.append(code)\n",
    "\n",
    "    return code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_code(code_snippets):\n",
    "\n",
    "    for code in code_snippets:\n",
    "        try:\n",
    "            ast.parse(code)\n",
    "\n",
    "            if \"import\" in code or \"system\" in code or \"exec\" in code:\n",
    "                print(\"Unsafe code\")\n",
    "                continue\n",
    "\n",
    "        except SyntaxError:\n",
    "            print(\"Invalid syntax\")\n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_output(output):\n",
    "\n",
    "    if not (isinstance(output, (pd.DataFrame, pd.Series, np.ndarray, list)) and output.shape[0] > 0 and not output.isnull().values.any()):\n",
    "        print(\"Invalid output\")\n",
    "        return\n",
    "\n",
    "    print(\"Valid output:\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf1de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96739765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df578211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef494a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d161b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177a8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62310a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48b25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c78d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
